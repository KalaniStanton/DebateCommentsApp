---
title: "Word Cloud Notebook"
output:
  html_document:
    code_folding: hide
    df_print: paged
    theme: cosmo
---

```{r setup, include=FALSE, warning=FALSE, echo=TRUE}
knitr::opts_chunk$set(cache = T)
options(warn=-1)
library(shiny)
library(plotly)
library(tm)
library(wordcloud)
library(tidytext)
library(wordcloud2)
library(hunspell)
library(purrr)
library(pluralize)
library(tidyverse)

datapath <- '/Users/viv/Downloads/DATA'
```  

# Data Cleaning

#### import data
```{r, message = FALSE}
# df <- read_csv(file.path('dataverse_files/debate_streaming.csv')) 
ts.df <- read_csv(file.path('ts_df.csv')) 
```


#### basic text scrub
```{r, eval = FALSE, echo = TRUE}
tokenized.df <- df %>% 
  distinct(text_id, .keep_all= TRUE) %>%  # remove duplicate comments
  select(comments, debate) %>%
  mutate(comments = gsub("[\r\n]", "", comments)) %>%  # text formatting
  mutate(comments = gsub("[â€™]", "'", comments)) %>%  # text formatting
  mutate(comments = gsub("[!]", " asdgfarhawg1 ", comments)) %>%  # text formatting
  mutate(comments = gsub("[?]", " adfhaerhgaesfa3 ", comments)) %>%  # text formatting
  mutate(comments = gsub("http", "", comments)) %>% 
  
  unnest_tokens(word, comments) %>%
  filter(!word %in% stop_words$word) %>%  # rm stop words
  filter(grepl("[A-Za-z]", word)) %>%  # remove anything with no letters [A-Za-z]
  mutate(word = gsub("'s$", "", word)) %>%  # remove possessives 's
  mutate(word = gsub("asdgfarhawg1", "!", word)) %>%  # reverse text formatting
  mutate(word = gsub("adfhaerhgaesfa3", "?", word))  # reverse text formatting 
```

singularize
```{r, eval = FALSE, echo = TRUE}
tokenized.singularized.df <- tokenized.df%>% 
  mutate(correction = singularize(word)) %>% 
  mutate(correction = gsub("[']$", "", correction)) %>% 
  filter(correction != word)
```

```{r, eval = FALSE, echo = FALSE}
# left_join(get_sentiments("nrc"))  # sentiment analysis
```

#### Spelling correction
```{r, eval = FALSE, echo = TRUE}
correct_spelling <- function(input) {
  output <- case_when(
    # manual corrections
    input == '0bama' ~ 'obama',
    input == '0ver' ~ 'over',
    input %in% c('!', '?', 'omg','demoncrat') ~ input,
    
    # if require spelling correction get first suggestion; NA if suggestions list is empty 
    !hunspell_check(input, dictionary('en_GB')) ~ hunspell_suggest(input, dictionary('en_US')) %>%
                                                    map(1, .default = NA) %>% unlist(),
    TRUE ~ input # if word is correct no change
  )
  
  # if input incorrectly spelled but no suggestions (NA), return input word
  return(ifelse(is.na(output), input, output))
}

# spell corrected singularized
tss.df <- tokenized.singularized.df %>% 
  mutate(correction = correct_spelling(correction))
tss.df %>% filter(word != correction)

# spell corrected non-singularized and remove posessives
ts.df <- tokenized.df %>% 
  mutate(correction = correct_spelling(word))
# write.csv(ts.df,'ts_df.csv')
# ts.df <- read_csv(file.path('ts_df.csv')) 
```

Manual spelling corrections
```{r, eval =F}
manual.retention <- c("unpresidential", "unamerican", "smh","nyt","abcnews","hes", "dt","letherspeak","jorgensen","jo","mfker","yrs","meds","covid","lol","dems","anymore","trump2020","lmao","wtf","blm","pos","yall","dem","maga","favor","haha","harris2020","antifa","stfu","dr","hahaha","wth","everytime","favoring","soooo","nobel","potus","aoc","favorite","behavior","dang","asshole","defund","tf","lockdown","aca","idk","hiden","labor","dnc","cheeto","kavanaugh","snl","lmao","sooo","aint","ppe","plexiglass","lil")
ts.df <- ts.imported.df %>% 
  mutate(correction = ifelse(word %in% manual.retention, word, correction)) %>% 
  mutate(correction = case_when(
    word == "bidens" ~ "Biden",
    TRUE ~ correction
  )) %>%
  mutate(correction = case_when(
    word == "lieing"~ "lying",
    word == "kool"~ "cool",
    word == "kamala"~ "Kamala",
    word == "ppl"~ "people",
    word == "pelosi"~ "Pelosi",
    word == "dont"~ "",
    word == "im"~ "",
    word == "didnt"~ "",
    word == "doesnt"~ "",
    word == "lier"~ "liar",
    word == "texas"~ "Texas",
    word == "paris"~ "Paris",
    word == "joes"~ "Joe",
    word == "covid19"~ "covid",
    word == "korea"~ "Korea",
    word == "cuz"~ "",
    word == "fauci"~ "Fauci",
    word == "whats"~ "",
    word == "isnt"~ "",
    word == "sooooo"~ "sooo",
    word == "soo"~ "sooo",
    word == "pense"~ "Pence",
    word == "u.s"~ "America",
    word == "isnt"~ "",
    word == "defunding"~ "defund",
    word == "melania"~ "Melania",
    word == "breonna"~ "Breonna",
    word == "tho"~ "",
    word == "ivanka"~ "Ivanka",
    word == "cuomo"~ "Cuomo",
    word == "gov"~ "government",
    word == "hitler"~ "Hitler",
    word == "hahahaha"~ "hahaha", 
    word == "hasnt"~ "",
    word == "pls"~ "please",
    TRUE ~ correction
  )) %>%
  mutate(correction = case_when(
    word == "trump"~ "Trump",
    word == "pence"~ "Pence",
    TRUE ~ correction
  ))
```

Spelling QC
```{r, eval = F}
ts.df %>% 
  filter(word != tolower(correction) & !correction == '') %>%
  group_by(word, correction) %>%
  count() %>%
  arrange(desc(n))

ts.df %>% 
  filter(correction == "Chris") %>%
  group_by(word, correction) %>%
  count() %>%
  arrange(desc(n))

ts.df %>% 
  count(correction) %>%
  arrange(desc(n))
```

final edits
```{r, eval = F}
ts.df <- ts.df %>% filter(correction != "")

ts.df <- ts.df %>%
  mutate(channel = substr(debate, 1, 3)) %>%
  select(channel, debate, word, correction)

unique(ts.df$channel)

# write.csv(ts.df,'ts_df.csv')
```

# Viz testing
```{r}
# wordcloud2(data = demoFreq)

debate.options <- unique(ts.df$debate)
temp.tab <- ts.df %>% filter(debate == debate.options[4]) %>% select(correction) %>% count(correction, name = "freq") %>% arrange(desc(freq))

temp.tab %>% wordcloud2(fontFamily = "didot", 
                        size = 1,  # <--------------- adjustable parameter "zoom" [1, 10]
                        minSize = 3,
                        rotateRatio = .15,
                        gridSize = 7.5,
                        ellipticity = 1,
                        backgroundColor = "#F0F3F5",
                        color = c("#181D27","#272F3F","#08090D","#2D334E"))

head(temp.tab %>% mutate(freq = paste0(round (freq / sum(freq)*100, digits=1), "%")), 100)
```

```{r, eval = FALSE}
library(shiny)

# MAIN
ts.df <- read_csv(file.path('ts_df.csv')) 
channel.options <- unique(ts.df$channel)
channel.options.pretty <- c("ABC","Fox","NBC")
wordcloud_backgroundcolor <- "#F0F3F5"  # <------------------------- color options for sara
wordcloud_textpallete <- c("#181D27","#272F3F","#08090D","#2D334E")  # <------------------------- color options for sara

# UI
ui <- fluidPage(
  sidebarLayout(
        sidebarPanel(
            sliderInput("usr.zoom",
                        "Word Cloud Zoom in/ out: ",
                        min = 1,
                        max = 10,
                        value = 1),
            selectInput("usr.channel", 
                        "Channel:",
                        choices = channel.options.pretty,
                        selected = "ABC")
        ),

        # Show a plot of the generated distribution
        mainPanel(
           wordcloud2Output("wcloud"),
           HTML("<br><br><br>"),
           dataTableOutput('table')
        )
    )
)

# SERVER
server <- function(input, output, session) {
  output$wcloud <- renderWordcloud2({
        usr.channel.no <- which(channel.options.pretty == input$usr.channel)
        temp.tab <- ts.df %>% 
                      filter(channel == channel.options[usr.channel.no]) %>% 
                      select(correction) %>% count(correction, name = "freq") %>%
                      arrange(desc(freq))

        temp.tab %>% wordcloud2(fontFamily = "didot", 
                        size = input$usr.zoom,  # <--------------- adjustable parameter "zoom" [1, 10]
                        minSize = 3,
                        rotateRatio = .15,
                        gridSize = 7.5,
                        ellipticity = 1,
                        backgroundColor = wordcloud_backgroundcolor,
                        color = wordcloud_textpallete)
    })
  
  output$table <- renderDataTable({
    temp.tab <- ts.df %>% 
      filter(channel == channel.options[usr.channel.no]) %>%
      select(correction) %>%
      count(correction, name = "Frequency") %>%
      arrange(desc(Frequency)) %>%
      rename(c("correction" = "Word")) %>%
      mutate(Proportion = paste0(round (Frequency / sum(Frequency) * 100, digits = 1), "%"))
  })
}

shinyApp(ui, server)
```

Scratch Work
```{r, eval = F}
usr.channel.no <- 1
```


